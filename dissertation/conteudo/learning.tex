\chapter{Learning Probabilistic Circuits}
\label{ch:learning}

As we have seen in \Cref{ch:pc}, inference in probabilistic circuits is, for the most part,
straightforward.  This is not so much the case when \emph{learning} PCs. Despite the uncomplicated
syntax, learning sufficiently expressive PCs in a principled way is comparatively harder to, say
the usual neural network. For a start, we are usually required to comply with smoothness and
decomposability to ensure marginalization at the least. This restriction excludes the possibility
of adopting any of the most popular neural network patterns or architectures used in deep learning
today. To make matters worse, constructing a PC graph more often than not involves costly
statistical tests that make learning their structure a challenge for high dimensional data.

In this chapter, we review the most popular PC structure learning algorithms, their pros and cons,
and more importantly, what can we learn from them to efficiently build scalable probabilistic
circuits. We broadly divide existing structure learners into three main categories:
divide-and-conquer (\divclass{}, \Cref{sec:divconq}), iterative methods (\iterclass{},
\Cref{sec:iterative}) and random approaches (\randclass{}, \Cref{sec:random}).

\section{Divide-and-Conquer Learning}
\label{sec:divconq}

Arguably the most popular approach to learning the structure of probabilistic circuits are
algorithms that follow a \emph{divide-and-conquer} scheme. This class of PC learning algorithms,
which here we denote by \divclass{}, are characterized by recursive calls over (usually mutually
exclusive) subsets of data in true divide-and-conquer fashion. This kind of procedure is more
clearly visualized by \textproc{LearnSPN}, the first (and most well-known) of its class.

Before we start however, we must first address how we denote data. Data is commonly represented as
a matrix where rows are assignments (of all variables), and columns are the values that each variable
takes at each assignment. Let $\set{D}\in\mathbb{R}^{m \times n}$ a matrix with $m$ rows and $n$
columns. We use $\set{D}_{i,j}$ to access an element of $\set{D}$ at the $i$-th row, $j$-th column
of matrix $\set{D}$. We denote by $\set{D}_{\set{i},\set{j}}$, where $\set{i}\subseteq
\left[1..n\right]$ and $\set{j}\subseteq\left[1..m\right]$ are sets of indices, a submatrix from
the extraction of the $\set{i}$ rows and $\set{j}$ columns of $\set{D}$. We use a colon as a
shorthand for selecting all rows or columns, e.g.\ $\set{D}_{:,:}=\set{D}$, $\set{D}_{:,j}$ is the
$j$-th column and $\set{D}_{i,:}$ is the $i$-th row.

\subsection{\textproc{LearnSPN}}

\begin{figure}[t]
  \begin{subfigure}[t]{0.48\textwidth}
    \begin{subfigure}{0.45\textwidth}
      \resizebox{\textwidth}{!}{
      \begin{tabular}{ccccc}
        \hline
        $A$ & $B$ & $C$ & $D$ & $E$\\
        \hline
        \rowcolor{boxgreen!70}
        0 & 1 & 0 & 0 & 1\\
        \rowcolor{boxgreen!70}
        1 & 0 & 1 & 1 & 1\\
        \rowcolor{boxblue!50}
        1 & 1 & 0 & 1 & 1\\
        \rowcolor{boxblue!50}
        0 & 0 & 1 & 0 & 0\\
        \rowcolor{boxgreen!70}
        1 & 1 & 0 & 1 & 0\\
        \rowcolor{boxblue!50}
        0 & 1 & 1 & 0 & 1\\
        \rowcolor{boxorange!60}
        1 & 0 & 1 & 1 & 1\\
        \rowcolor{boxorange!60}
        1 & 1 & 0 & 0 & 0\\
        \rowcolor{boxblue!50}
        0 & 1 & 1 & 0 & 1\\
        \hline
      \end{tabular}
      }
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
      \resizebox{\textwidth}{!}{
      \begin{tikzpicture}
        \newSumNode[fill=boxpink!50]{r}{0,0};
        \newProdNode[fill=boxgreen!70]{p1}{$(r) + (-1.5,-1.5)$};
        \newProdNode[fill=boxorange!60]{p2}{$(r) + (0,-1.5)$};
        \newProdNode[fill=boxblue!50]{p3}{$(r) + (1.5,-1.5)$};
        \draw[edge] (r) -- node[midway,above left] {$\frac{3}{9}$} (p1);
        \draw[edge] (r) -- node[midway,left] {$\frac{2}{9}$} (p2);
        \draw[edge] (r) -- node[midway,above right] {$\frac{4}{9}$} (p3);
      \end{tikzpicture}
      }
    \end{subfigure}
    \caption{}
  \end{subfigure}
  \begin{subfigure}[t]{0.48\textwidth}
    \begin{subfigure}{0.45\textwidth}
      \newcolumntype{x}{>{\columncolor{boxgreen!70}}c}
      \newcolumntype{y}{>{\columncolor{boxorange!60}}c}
      \newcolumntype{z}{>{\columncolor{boxblue!50}}c}
      \resizebox{\textwidth}{!}{
      \begin{tabular}{xyyzx}
        \hline
        \multicolumn{1}{c}{$A$} & \multicolumn{1}{c}{$B$} & \multicolumn{1}{c}{$C$} &
        \multicolumn{1}{c}{$D$} & \multicolumn{1}{c}{$E$}\\
        \hline
        0 & 1 & 0 & 0 & 1\\
        1 & 0 & 1 & 1 & 1\\
        1 & 1 & 0 & 1 & 1\\
        0 & 0 & 1 & 0 & 0\\
        1 & 1 & 0 & 1 & 0\\
        0 & 1 & 1 & 0 & 1\\
        1 & 0 & 1 & 1 & 1\\
        1 & 1 & 0 & 0 & 0\\
        0 & 1 & 1 & 0 & 1\\
        \hline
      \end{tabular}
      }
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
      \resizebox{\textwidth}{!}{
      \begin{tikzpicture}
        \newProdNode[fill=boxpink!50]{r}{0,0};
        \newSumNode[label=below:{$\{A,E\}$},fill=boxgreen!70]{s1}{$(r) + (-1.5,-1.5)$};
        \newSumNode[label=below:{$\{B,C\}$},fill=boxorange!60]{s2}{$(r) + (0,-1.5)$};
        \newSumNode[label=below:{$\{D\}$},fill=boxblue!50]{s3}{$(r) + (1.5,-1.5)$};
        \draw[edge] (r) -- (s1); \draw[edge] (r) -- (s2); \draw[edge] (r) -- (s3);
      \end{tikzpicture}
      }
    \end{subfigure}
    \caption{}
  \end{subfigure}
  \caption{\textproc{LearnSPN} assigns either rows (a) or columns (b) for sum and product nodes
    respectively. For sums, their edge weights are set proportionally to the assignments. For
    product children, scopes are defined by which columns are assigned to them.}
  \label{fig:learnspn}
\end{figure}

Recall the semantics of sum and product nodes in a smooth and decomposable probabilistic circuit.
A sum is a mixture of distributions $p(\set{X})=\sum_{i=1}^m w_i\cdot p_i(\set{X})$ whose children
scopes are all the same. A product is a factorization $p(\set{X}_1,\ldots,\set{X}_n)=\prod_{i=1}^n
p(\set{X}_i)$, implying that $\set{X}_i\indep\set{X}_j$ for $i,j\in [n]$ and $i\neq j$.
\textproc{LearnSPN} \citep{gens13} exploits these semantics in an intuitive and uncomplicated
manner: sum children are defined by sub-PCs learned from similar (by some arbitrary metric)
assignments, and product children are sub-PCs learned from data conditioned on the variables
defined by their scope. In practice, this means that, for a dataset $\set{D}\in\mathbb{R}^{m\times
n}$, sums assign rows to their children, while product children are assigned columns. This
procedures continues recursively until data are reduced to a $k\times 1$ matrix, in which case a
univariate distribution acting as input node is learned from it. This recursive procedure is shown
more formally in \Cref{alg:learnspn}.

\begin{algorithm}[t]
  \caption{\textproc{LearnSPN}}\label{alg:learnspn}
  \begin{algorithmic}[1]
    \Require Data $\set{D}$, whose columns are indexed by variables $\set{X}$
    \Ensure A smooth and decomposable probabilistic circuit learned from $\set{D}$
    \IIf{$|\set{X}|=1$}{\textbf{return} an input node learned from $\set{D}$}
    \NIElse
      \State Find scope partitions $\set{X}_1,\ldots,\set{X}_t\subseteq\set{X}$ st
        $\set{X}_i\indep\set{X}_j$ for $i\neq j$
      \IIf{$k>1$}{\textbf{return} $\prod_{j=1}^t \textproc{LearnSPN}(\set{D}_{:,\set{X}_j},
        \set{X}_j)$}
      \NIElse
        \State Find subsets of data $\set{x}_1,\ldots,\set{x}_k\subseteq\set{D}$ st all assignments
          within $\set{x}_i$ are all similar
        \State \textbf{return} $\sum_{i=1}^k \frac{|\set{x}_i|}{|\set{D}|}\cdot
          \textproc{LearnSPN}(\set{x}_i,\set{X})$
      \EndNIElse
    \EndNIElse
  \end{algorithmic}
\end{algorithm}

Notably, \citep{gens13} purposely does not strictly specify which techniques should be used for
assigning rows and columns, although they do provide empirical results on a particular form of
\textproc{LearnSPN} where row assignments are computed through EM clustering and products by
pairwise G-testing. Instead, they call the algorithm a \emph{schema} that incorporates several
actual learning algorithms whose concrete form depends on the choice of how to split data.

\subsubsection{Complexity}

To be able to analyze the complexity of \textproc{LearnSPN}, we assume a common implementation
where sums are learned from $k$-means clustering, and products through pairwise G-testing. We know
learning sums is efficient: $k$-means takes $\bigo(n\cdot k\cdot m\cdot c)$ time, where $k$ is the
number of clusters and $c$ the number of iterations to be run. Products, on the other hand, are
much more costly. The naÃ¯ve approach would be to compute whether $X_i\indep X_j$ for every possible
combination. This is clearly quadratic on the number of variables
$\bigo\left(\binom{m}{2}=\frac{m!}{2(m-2)!}\right)$ assuming an $\bigo(1)$ oracle for independence
testing. In reality, G-test takes $\bigo(n\cdot m)$ time, as we must compute a ratio of observed
versus expected values for each cell in the contingency table. This brings the total runtime for
products to a whopping $\bigo\left(n\cdot m^3\right)$, prohibitive to any reasonably large dataset.
In terms of space, independence tests most commonly used require either a correlation (for
continuous data) or contingency (for discrete data) matrix that takes up $\bigo(m^2)$ space,
another barrier for scaling up to high dimensional data.

Alternatively, instead of computing the G-test for every possible combination of variables,
\citep{gens13} constructs an independence graph $\mathcal{G}$ whose nodes are variables and edges
indicate whether two variables are statistically dependent. Within this context, the variable
partitions we attribute to product children are exactly the connected components of $\mathcal{G}$,
meaning it suffices testing only some combinations. Even so, this heuristic is still quadratic
worst case. \Cref{fig:indepgraph} shows $\mathcal{G}$, the spanning forest resulted from the
connected component heuristic, and the equivalent product node from this decomposition.

\begin{figure}[t]
  \begin{subfigure}[t]{0.3\textwidth}
    \centering
    \resizebox{0.8\textwidth}{!}{
    \begin{tikzpicture}
      \node[regular polygon,regular polygon sides=8,minimum size=4cm] (p) {};
      \node[circle,fill=boxorange!80] (p1) at (p.corner 1) {$A$};
      \node[circle,fill=boxpurple!60] (p2) at (p.corner 2) {$B$};
      \node[circle,fill=boxgreen] (p3) at (p.corner 3) {$C$};
      \node[circle,fill=boxred!70] (p4) at (p.corner 4) {$D$};
      \node[circle,fill=boxpink!50] (p5) at (p.corner 5) {$E$};
      \node[circle,fill=boxgray] (p6) at (p.corner 6) {$F$};
      \node[circle,fill=boxgoldenrod!70] (p7) at (p.corner 7) {$G$};
      \node[circle,fill=boxblue!50] (p8) at (p.corner 8) {$H$};
      \draw[thick] (p1) -- (p2) -- (p3); \draw[thick] (p1) -- (p3);
      \draw[thick] (p3) -- (p4); \draw[thick] (p1) -- (p4);
      \draw[thick] (p5) -- (p6) -- (p7); \draw[thick] (p5) -- (p7);
    \end{tikzpicture}
    }
    \caption{}
  \end{subfigure}
  \begin{subfigure}[t]{0.3\textwidth}
    \centering
    \resizebox{0.8\textwidth}{!}{
    \begin{tikzpicture}
      \node[regular polygon,regular polygon sides=8,minimum size=4cm] (p) {};
      \node[circle,fill=boxorange!80] (p1) at (p.corner 1) {$A$};
      \node[circle,fill=boxpurple!60] (p2) at (p.corner 2) {$B$};
      \node[circle,fill=boxgreen] (p3) at (p.corner 3) {$C$};
      \node[circle,fill=boxred!70] (p4) at (p.corner 4) {$D$};
      \node[circle,fill=boxpink!50] (p5) at (p.corner 5) {$E$};
      \node[circle,fill=boxgray] (p6) at (p.corner 6) {$F$};
      \node[circle,fill=boxgoldenrod!70] (p7) at (p.corner 7) {$G$};
      \node[circle,fill=boxblue!50] (p8) at (p.corner 8) {$H$};
      \draw[thick] (p1) -- (p2); \draw[thick] (p1) -- (p3);
      \draw[thick] (p1) -- (p4); \draw[thick] (p1) -- (p4);
      \draw[thick] (p5) -- (p6); \draw[thick] (p5) -- (p7);
    \end{tikzpicture}
    }
    \caption{}
  \end{subfigure}
  \begin{subfigure}[t]{0.3\textwidth}
    \centering
    \begin{tikzpicture}
      \newProdNode[fill=boxgreen]{r}{0,0};
      \newSumNode[label=below:{$\{A,B,C,D\}$},fill=boxorange!80]{s1}{$(r) + (-1.25,-2.5)$};
      \newSumNode[label=below:{$\{E,F,G\}$},fill=boxpink!50]{s2}{$(r) + (0,-1.75)$};
      \newSumNode[label=below:{$\{H\}$},fill=boxblue!50]{s3}{$(r) + (1.25,-1.0)$};
      \draw[edge] (r) -- (s1); \draw[edge] (r) -- (s2); \draw[edge] (r) -- (s3);
    \end{tikzpicture}
    \caption{}
  \end{subfigure}
  \caption{The pairwise (in)dependence graph where each node is a variable. In (a) we show the full
    graph, computing independence tests for each pair of variables in $\bigo(m^2)$. However, it
    suffices to compute for only the connected components (b), saving up pairwise computation time
    for reachable nodes.  The resulting product node and scope partitioning is shown in (c).}
  \label{fig:indepgraph}
\end{figure}

\subsubsection{Pros and cons}

\paragraph{Pros.} Perhaps the main factor for \textproc{LearnSPN}'s popularity is how easily
implementable, intuitive and modular it is. Even more remarkably, it is an empirically competitive
PC learning algorithm despite its age, serving as a baseline for most subsequent works in PC
literature. Lastly, the fact that each recursive call from \textproc{LearnSPN} is completely
independent from each the other makes it an attractive candidate for CPU parallelization.

\paragraph{Cons.} Debatably, one of the key weakness of \textproc{LearnSPN} is its tree-shaped
computational graph, meaning that they are strictly less succint compared to non-tree DAG PCs
\citep{martens14}. In terms of runtime efficiency, the algorithm struggles on high dimensional
data due to the complexity involved in computing costly statistical tests. Despite
\Cref{alg:learnspn} giving the impression that no hyperparameter tuning is needed for
\textproc{LearnSPN}, in practice the modules for learning sums and products often take many
parameters, most of which (if not all) are exactly the same for every recursive call. This can have
a negative impact on the algorithm's performance, since the same parameters are repeatedly used
even under completely different data.

\subsection{\textproc{ID-SPN}}

A subtle yet effective way of improving the performance of \textproc{LearnSPN} is to consider
tractable probabilistic models over many variables as input nodes instead of univariate
distributions. \textproc{ID-SPN} \citep{rooshenas14} does so by assuming that input nodes are
Markov networks. Further, instead of blindly applying the recursion over subsequent sub-data, it
attempts to compute some metric of quality from each node. The worst scored node is then replaced
with a \textproc{LearnSPN}-like tree. This is repeated until no significant increase in likelihood
is observed. \Cref{alg:idspn} shows the \textproc{ID-SPN} pipeline, where \textproc{ExtendID} is
used in line \ref{alg:idspn:line:extend} to grow the circuit in a divide-and-conquer fashion. The
name \textproc{ID-SPN} comes from \emph{direct} variable interactions, meaning the relationships
modeled through the Markov networks as input nodes; and \emph{indirect} interactions brought from
the latent variable interpretation of sum nodes.

\begin{algorithm}[t]
  \caption{\textproc{ExtendID}}\label{alg:extendid}
  \begin{algorithmic}[1]
    \Require Data $\set{D}$, whose columns are indexed by variables $\set{X}$, and memoization
      function $\mathcal{M}$
    \Ensure A smooth and decomposable probabilistic circuit learned from $\set{D}$
    \State Find scope partitions $\set{X}_1,\ldots,\set{X}_t\subseteq\set{X}$ st
    \If{$k>1$}
      \For{each $j\in\left[t\right]$}
        \State $\Node_j\gets\textproc{LearnMarkov}(\set{D}_{:,\set{X}_j},\set{X}_j)$
        \State Associate $\mathcal{M}(\Node_j)$ with $\set{D}_{:,\set{X}_j}$ and $\set{X}_j$
      \EndFor
      \State \textbf{return} $\prod_{j=1}^t \Node_j$
    \Else
      \State Find subsets of data $\set{x}_1,\ldots,\set{x}_k\subseteq\set{D}$ st all assignments
        within $\set{x}_i$ are all similar
      \For{each $i\in\left[k\right]$}
        \State $\Node_i\gets\textproc{LearnMarkov}(\set{x}_i,\set{X})$
        \State Associate $\mathcal{M}(\Node_i)$ with $\set{x}_i$ and $\set{X}$
      \EndFor
      \State \textbf{return} $\sum_{i=1}^k \frac{|\set{x}_i|}{|\set{D}|}\cdot\Node_i$
    \EndIf
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}[t]
  \caption{\textproc{ID-SPN}}\label{alg:idspn}
  \begin{algorithmic}[1]
    \Require Data $\set{D}$, whose columns are indexed by variables $\set{X}$
    \Ensure A smooth and decomposable probabilistic circuit learned from $\set{D}$
    \State Create a single-node PC: $\mathcal{C}\gets\textproc{LearnMarkov}(\set{D},\set{X})$
    \State Let $\mathcal{M}$ a memoization function associating a node with a dataset and scope
    \State Call $\mathcal{C}'$ a copy of $\mathcal{C}$
    \While{improving $\mathcal{C}$ yields better likelihood}
      \State Pick worse node $\Node$ from $\mathcal{C}'$
      \State Extract sub-data $\set{D}'$ and sub-scope $\set{X}'$ from $\mathcal{M}(\Node)$
      \State Replace $\Node$ with $\textproc{ExtendID}(\set{D}',\set{X}',\mathcal{M})$\label{alg:idspn:line:extend}
      \IIf{$\mathcal{C}'$ has better likelihood than $\mathcal{C}$}{$\mathcal{C}\gets\mathcal{C}$}
    \EndWhile
    \State \textbf{return} $\mathcal{C}$
  \end{algorithmic}
\end{algorithm}

With respect to its implementation, \textproc{ID-SPN} is as modular as \textproc{LearnSPN} in the
sense that the data partitioning is left as a subroutine. Indeed, even the choice of input
distributions is customizable: although \citeauthor{rooshenas14} recommend Markov networks, any
tractable distribution will do. Despite this seemingly small change compared to the original
\textproc{LearnSPN} algorithm, \textproc{ID-SPN} seems to perform better compared to its
counterpart most of the time \citep{rooshenas14,jaini18a}, although at a cost to learning speed.
Further, because of the enormous parameter space brought by having to learn Markov networks as
inputs \emph{and} perform the optimizations from sums and products, grid search hyperparameter
tuning is infeasible. \citep{rooshenas14} recommend random search \citep{bergstra12a} as an
alternative.

\begin{figure}[t]
  \resizebox{\textwidth}{!}{
  \begin{tikzpicture}
    % Markov 1
    \node[fill=boxteal] (a) at (0,0) {$A$};
    \node[fill=boxorange!80] (b) at ($(a) + (1,-1)$) {$B$};
    \node[fill=boxpink!50] (c) at ($(a) + (1,0)$) {$C$};
    \node[fill=boxgoldenrod!70] (d) at ($(a) + (0,-1)$) {$D$};
    \node[fill=boxred!70] (e) at ($(d) + (0,-1)$) {$E$};
    \node[fill=boxpurple!60] (f) at ($(b) + (0,-1)$) {$F$};
    \draw (a) -- (b); \draw (b) -- (c);
    \draw (a) -- (c); \draw (a) -- (d);
    \draw (e) -- (f); \draw (f) -- (d);
    \draw[red,very thick,dashed] (-0.5,0.5) rectangle ($(f) + (0.5,-0.5)$);
    \node at ($(e) + (0.5,-1)$) {Initial Markov network};

    \draw[edge,line width=0.2cm,red] (2,-1) -- (3.5,-1);

    \newProdNode[fill=boxgreen]{r}{6.25,0};

    % Markov 2
    \node[fill=boxpink!50] (a) at ($(r) + (0.75,-1)$) {$A$};
    \node[fill=boxteal] (b) at ($(a) + (1,0)$) {$B$};
    \node[fill=boxorange!80] (c) at ($(b) + (0,-1)$) {$C$};
    \draw (a) -- (b); \draw (b) -- (c);
    \draw[edge] (r) -- ($(a) + (0.5,0.5)$);
    \draw[red,very thick,dashed] ($(a) + (-0.5,0.5)$) rectangle ($(c) + (0.5,-0.5)$);

    % Markov 3
    \node[fill=boxgoldenrod!70] (f) at ($(r) + (-0.75,-1)$) {$F$};
    \node[fill=boxred!70] (d) at ($(f) + (-1,0)$) {$D$};
    \node[fill=boxpurple!60] (e) at ($(d) + (1,-1)$) {$E$};
    \draw (d) -- (f); \draw (e) -- (d);
    \draw[edge] (r) -- ($(d) + (0.5,0.5)$);
    \draw[boxdgray,thick,dashed] ($(d) + (-0.5,0.5)$) rectangle ($(e) + (0.5,-0.5)$);

    \node (i1) at ($(r) + (0,-3)$) {Iteration 1};

    \draw[edge,line width=0.2cm,red] ($(b) + (1,0)$) -- ($(b) + (2.5,0)$);

    \newProdNode[fill=boxgreen]{r}{14.5,0.5};
    \newSumNode[fill=boxbrown!60]{s}{$(r) + (2.0,-0.5)$};
    \draw[edge] (r) -- (s);

    \begin{scope}[local bounding box=m1]
      \node[fill=boxorange!80] (b) at ($(s) + (-1.5,-1)$) {$B$};
      \node[fill=boxteal] (a) at ($(b) + (-1,0)$) {$A$};
      \node[fill=boxpink!50] (c) at ($(b) + (0,-1)$) {$C$};
      \draw (a) -- (b); \draw (a) -- (c);
      \draw[boxdgray,thick,dashed] ($(a) + (-0.5,0.5)$) rectangle ($(c) + (0.5,-0.5)$);
    \end{scope}
    \draw[edge] (s) -- (m1.north);

    \begin{scope}[local bounding box=m2]
      \node[fill=boxteal] (a) at ($(s) + (0.0,-1.5)$) {$A$};
      \node[fill=boxorange!80] (b) at ($(a) + (1,0)$) {$B$};
      \node[fill=boxpink!50] (c) at ($(b) + (0,-1)$) {$C$};
      \draw (a) -- (c); \draw (b) -- (c); \draw (a) -- (b);
      \draw[boxdgray,thick,dashed] ($(a) + (-0.5,0.5)$) rectangle ($(c) + (0.5,-0.5)$);
    \end{scope}
    \draw[edge] (s) -- (m2.north);

    % Markov 3
    \node[fill=boxgoldenrod!70] (f) at ($(r) + (-2,-1)$) {$F$};
    \node[fill=boxred!70] (d) at ($(f) + (-1,0)$) {$D$};
    \node[fill=boxpurple!60] (e) at ($(d) + (1,-1)$) {$E$};
    \draw (d) -- (f); \draw (e) -- (d);
    \draw[edge] (r) -- ($(d) + (0.5,0.5)$);
    \draw[boxdgray,thick,dashed] ($(d) + (-0.5,0.5)$) rectangle ($(e) + (0.5,-0.5)$);

    \node at ($(r) + (0,-3.5)$) {Iteration 2};
  \end{tikzpicture}
  }
  \caption{Two iterations of \textproc{ID-SPN}, where the contents inside the dashed line are
  Markov networks. The red color indicates that a node has been chosen as the best candidate for an
  extension with \textproc{ExtendID}. Although here we only extend input nodes, inner nodes can in
  fact be extended as well.}
\end{figure}

\subsubsection{Complexity}

As \textproc{ID-SPN} is a special case of \textproc{LearnSPN}, the analysis for the sums and
products subroutines holds. The only difference is on the runtime complexity for learning input
nodes and the convergence rate for \textproc{ID-SPN}. Assuming input nodes are learned from the
method suggested by \citet{rooshenas14}, which involves learning a probabilistic circuit from a
Markov network \citep{lowd13a}, then each ``input'' node takes time $\bigo(i\cdot c(k\cdot n+m))$,
where $i$ is the number of iterations to run, $c$ is the size of the generated PC, and constant $k$
is a bound on the number of candidate improvements to the circuit, which can grow exponentially for
multi-valued variables. Importantly, opposite from \textproc{LearnSPN} where we only learn input
nodes once per call \emph{if} data is univariate, \textproc{ID-SPN} requires learning multiple
multivariate inputs for \emph{every} \textproc{ExtendID} call.

\subsubsection{Pros and Cons}

\paragraph{Pros.} If we assume any multivariate distribution in place of Markov networks, PCs
learned from \textproc{ID-SPN} are strictly more expressive than ones learned from
\textproc{LearnSPN}, as input nodes could potentially be replaced with \textproc{LearnSPN}
distributions. Additionally, the modularity inherited from \textproc{LearnSPN} allows
\textproc{ID-SPN} to adapt to data according to expert knowledge, bringing some flexibility to the
algorithm.

\paragraph{Cons.} Unfortunately, most of the disadvantages from \textproc{LearnSPN} also apply to
\textproc{ID-SPN}. Just like \textproc{LearnSPN}, independence tests are more often than not a
bottleneck for most executions with resonably large number of variables. However, \textproc{ID-SPN}
relies on a likelihood improvement for the computational graph to be extended, which ends up
curbing the easy parallelization aspect of \textproc{LearnSPN}. Besides, the complexity involved in
learning Markov networks (or any other complex multivariate distribution as input node) carries a
heavy weight during learning. This, coupled with the fact that hyperparameter tuning in the huge
parameter space of \textproc{ID-SPN} must be done by a random search method, can take a heavy price
in terms of learning time.

\subsection{\textproc{Prometheus}}

So far, we have only considered structure learning algorithms that produce tree-shaped circuits.
Even though \textproc{ID-SPN} \emph{might} produce non-tree graphs at the input nodes depending on
the choice of families of multivariate distributions, it does not do so as a rule. We now turn our
attention to a PC learner that \emph{does} generate non-tree computational graphs in a
divide-and-conquer manner.

Recall that in both \textproc{LearnSPN} and \textproc{ID-SPN} the scope partitioning is done
greedily; we define a graph encoding the pairwise (in)dependencies of variables and greedily search
for connected components by comparing independence test results with some correlation threshold,
adding an edge if the correlation is sufficiently high. The choice of this threshold is often
arbitrary and subject to hyperparameter tuning during learning, which is especially worrying when
dealing with high dimensional data. In this section we review \textproc{Prometheus}, a
divide-and-conquer \textproc{LearnSPN}-like PC learning algorithm with two main features that stand
out compared to the last two methods we have seen so far: (1) it requires no hyperparameter tuning
for variable partitionings, and (2) accepts a more scalable alternative to computing all pairwise
correlations.

\begin{figure}[t]
  \begin{subfigure}[t]{0.25\textwidth}
    \centering
    \resizebox{0.9\textwidth}{!}{
    \begin{tikzpicture}
      \node[regular polygon,regular polygon sides=5,minimum size=4cm] (p) {};
      \node[circle,fill=boxorange!80] (p1) at (p.corner 1) {$A$};
      \node[circle,fill=boxred!70] (p2) at (p.corner 2) {$B$};
      \node[circle,fill=boxpink!50] (p3) at (p.corner 3) {$C$};
      \node[circle,fill=boxgoldenrod!70] (p4) at (p.corner 4) {$D$};
      \node[circle,fill=boxblue!50] (p5) at (p.corner 5) {$E$};
      \draw[thick] (p1) -- node[midway,above left] {$0.8$} (p2);
      \draw[thick] (p1) -- node[midway,left,yshift=0.1cm] {$0.2$} (p3);
      \draw[thick] (p1) -- node[midway,right,yshift=0.1cm] {$0.4$} (p4);
      \draw[thick] (p1) -- node[midway,above right] {$0.3$} (p5);
      \draw[thick] (p2) -- node[midway,below left] {$0.6$} (p3);
      \draw[thick] (p2) -- node[midway,below left,xshift=0.2cm] {$0.4$} (p4);
      \draw[thick] (p2) -- node[midway,above] {$0.1$} (p5);
      \draw[thick] (p3) -- node[midway,below] {$0.9$} (p4);
      \draw[thick] (p3) -- node[midway,below right,xshift=-0.2cm] {$0.5$} (p5);
      \draw[thick] (p4) -- node[midway,right] {$0.7$} (p5);
    \end{tikzpicture}
    }
    \caption{}
  \end{subfigure}
  \begin{subfigure}[t]{0.25\textwidth}
    \centering
    \resizebox{0.9\textwidth}{!}{
    \begin{tikzpicture}
      \node[regular polygon,regular polygon sides=5,minimum size=4cm] (p) {};
      \node[circle,fill=boxorange!80] (p1) at (p.corner 1) {$A$};
      \node[circle,fill=boxred!70] (p2) at (p.corner 2) {$B$};
      \node[circle,fill=boxpink!50] (p3) at (p.corner 3) {$C$};
      \node[circle,fill=boxgoldenrod!70] (p4) at (p.corner 4) {$D$};
      \node[circle,fill=boxblue!50] (p5) at (p.corner 5) {$E$};
      \draw[very thick,blue] (p1) -- node[midway,above left,xshift=-0.1cm,yshift=0.1cm] {$\mathbf{0.8}$} node[fill=white,inner sep=1pt] {$e_2$} (p2);
      \draw[very thick,red] (p2) -- node[midway,left,xshift=-0.1cm,yshift=-0.1cm] {$\mathbf{0.6}$} node[fill=white,inner sep=1pt] {$e_4$} (p3);
      \draw[very thick,boxdgray] (p3) -- node[midway,below,yshift=-0.1cm] {$\mathbf{0.9}$} node[fill=white,inner sep=1pt] {$e_1$} (p4);
      \draw[very thick,orange!80] (p4) -- node[midway,right,xshift=0.1cm,yshift=-0.1cm] {$\mathbf{0.7}$} node[fill=white,inner sep=1pt] {$e_3$} (p5);
    \end{tikzpicture}
    }
    \caption{}
  \end{subfigure}
  \begin{subfigure}[t]{0.45\textwidth}
    \centering
    \resizebox{\textwidth}{!}{
    \begin{tikzpicture}
      \newSumNode[fill=boxgreen]{r}{0,0};
      \newProdNode[fill=blue!50]{p1}{$(r) + (-3,-1)$};
      \newProdNode[fill=red!60]{p2}{$(r) + (-1,-1)$};
      \newProdNode[fill=boxdgray!80]{p3}{$(r) + (1,-1)$};
      \newProdNode[fill=orange!80]{p4}{$(r) + (3,-1)$};
      \newSumNode[label=below:{$\{A,B,C\}$},fill=green!80!black]{s1}{$(r) + (-3.5,-3.0)$};
      \newSumNode[label=below:{$\{D,E\}$},fill=green!80!black]{s2}{$(r) + (-2.5,-2.5)$};
      \newSumNode[label=below:{$\{B,C\}$},fill=green!80!black]{s3}{$(r) + (-1.5,-2.0)$};
      \newSumNode[label=below:{$\{A\}$},fill=green!80!black]{s4}{$(r) + (-0.5,-2.0)$};
      \newSumNode[label=below:{$\{D\}$},fill=green!80!black]{s5}{$(r) + (0.5,-2.0)$};
      \newSumNode[label=below:{$\{E\}$},fill=green!80!black]{s6}{$(r) + (1.5,-2.0)$};
      \newSumNode[label=below:{$\{B\}$},fill=green!80!black]{s7}{$(r) + (2.5,-2.0)$};
      \newSumNode[label=below:{$\{C\}$},fill=green!80!black]{s8}{$(r) + (3.5,-2.0)$};
      \draw[edge] (r) -- (p1.north);
      \draw[edge] (r) -- (p2.north);
      \draw[edge] (r) -- (p3.north);
      \draw[edge] (r) -- (p4.north);
      \draw[edge,blue!80] (p1) -- (s1.north);
      \draw[edge,blue!80] (p1) -- (s2.north);
      \draw[edge,red!80] (p2) -- (s2.north);
      \draw[edge,red!80] (p2) -- (s3.north);
      \draw[edge,red!80] (p2) -- (s4.north);
      \draw[edge,boxdgray!80] (p3) -- (s3.north);
      \draw[edge,boxdgray!80] (p3) -- (s4.north);
      \draw[edge,boxdgray!80] (p3) -- (s5.north);
      \draw[edge,boxdgray!80] (p3) -- (s6.north);
      \draw[edge,orange!80] (p4) -- (s4.north);
      \draw[edge,orange!80] (p4) -- (s5.north);
      \draw[edge,orange!80] (p4) -- (s6.north);
      \draw[edge,orange!80] (p4) -- (s7.north);
      \draw[edge,orange!80] (p4) -- (s8.north);
    \end{tikzpicture}
    }
    \caption{}
  \end{subfigure}
  \caption{The fully connected correlation graph (a) with weights as the pairwise correlation
    measurements for each pair of variables; the maximum spanning tree for determining
    decompositions (b); and the mixture of decompositions (c). Colors in (b) match their
    partitionings in (c).}
  \label{fig:prometheus}
\end{figure}

Let $\mathcal{G}$ the independence graph for scope $\set{X}=\{X_1,X_2,\ldots,X_m\}$. Remember that
$\mathcal{G}$'s vertices are $\set{X}$ and each (undirected) edge $\overline{X_i X_j}$ coming from
$X_i$ to $X_j$ means that $X_i\notindep X_j$. Previously, we constructed $\mathcal{G}$ by comparing
the output of an independence test (such as the G-test) against a threshold (e.g.\ a sufficiently
low $p$-value). Instead, suppose $\mathcal{G}$ is fully connected and that we attribute weights
corresponding to a correlation metric of $X_i$ against $X_j$ for each edge (e.g.\ Pearson's
correlation coefficient). The \emph{maximum spanning tree} (MST) of $\mathcal{G}$, here denoted by
$\mathcal{T}$, defines a graph where the removal of any edge in $\mathcal{T}$ partitions the
component into two subcomponents. Let $e_i$ the $i$-th lowest (weight) valued edge;
\textproc{Prometheus} obtains a set of decompositions by iteratively removing edges from $e_1$ to
$e_{|\set{X}|-1}$. In other words, the algorithm constructs a product node for each decomposition,
assigning the scope of each child as the scope of each component at each edge removal. These
products are then joined together by a parent sum node that acts as a mixture of decompositions.
\Cref{fig:prometheus} shows an example of $\mathcal{T}$, the subsequent decompositions, and the
resulting mixture of decompositions.

\begin{algorithm}[t]
  \caption{\textproc{Prometheus}}\label{alg:prometheus}
  \begin{algorithmic}[1]
    \Require Data $\set{D}$, whose columns are indexed by variables $\set{X}$
    \Ensure A smooth and decomposable probabilistic circuit learned from $\set{D}$
    \IIf{$|\set{X}|=1$}{\textbf{return} an input node learned from $\set{D}$}
    \NIElse
      \State Find subsets of data $\set{x}^{(1)},\ldots,\set{x}^{(k)}\subseteq\set{D}$ st all assignments
        within $\set{x}^{(i)}$ are all similar
      \State Call $\mathcal{S}$ the set of all scopes seen so far
      \For{each $\set{x}^{(i)}$}
        \State $\mathcal{T}\gets\textproc{CorrelationMST}(\set{x}^{(i)},set{X})$
        \For{each weighted edge $e_i$ in \mathcal{T} in decreasing order}
          \State Remove edge $e_i$ from $\mathcal{T}$
          \State Save $\set{S}_1,\ldots,\set{S}_t$, the scopes of each component in $\mathcal{T}$, to $\mathcal{S}$
        \EndFor
        \State $\Prod_i\gets\prod_{\set{S}\in\mathcal{S}}\textproc{Prometheus}(\set{x}^{(i)}_{:,\set{S}},\set{S})$
      \EndFor
      \State \textbf{return} $\sum_{i=1}^k \Prod_i$
    \EndNIElse
  \end{algorithmic}
\end{algorithm}


\section{Iterative Learning}
\label{sec:iterative}

\section{Random Learning}
\label{sec:random}
