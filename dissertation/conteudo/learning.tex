\chapter{Learning Probabilistic Circuits}
\label{ch:learning}

As we have seen in \Cref{ch:pc}, inference in probabilistic circuits is, for the most part,
straightforward.  This is not so much the case when \emph{learning} PCs. Despite the uncomplicated
syntax, learning sufficiently expressive PCs in a principled way is comparatively harder to, say
the usual neural network. For a start, we are usually required to comply with smoothness and
decomposability to ensure marginalization at the least. This restriction excludes the possibility
of adopting any of the most popular neural network patterns or architectures used in deep learning
today. To make matters worse, constructing a PC graph more often than not involves costly
statistical tests that make learning their structure a challenge for high dimensional data.

In this chapter, we review the most popular PC structure learning algorithms, their pros and cons,
and more importantly, what can we learn from them to efficiently build scalable probabilistic
circuits. We broadly divide existing structure learners into three main categories:
divide-and-conquer (\divclass{}, \Cref{sec:divconq}), iterative methods (\iterclass{},
\Cref{sec:iterative}) and random approaches (\randclass{}, \Cref{sec:random}).

\section{Divide-and-Conquer Learning}
\label{sec:divconq}

Arguably the most popular approach to learning the structure of probabilistic circuits are
algorithms that follow a \emph{divide-and-conquer} scheme. This class of PC learning algorithms,
which here we denote by \divclass{}, are characterized by recursive calls over (usually mutually
exclusive) subsets of data in true divide-and-conquer fashion. This kind of procedure is more
clearly visualized by \textproc{LearnSPN}, the first (and most well-known) of its class.

Before we start however, we must first address how we denote data. Data is commonly represented as
a matrix where rows are assignments (of all variables), and columns are the values that each variable
takes at each assignment. Let $\set{D}\in\mathbb{R}^{m \times n}$ a matrix with $m$ rows and $n$
columns. We use $\set{D}_{i,j}$ to access an element of $\set{D}$ at the $i$-th row, $j$-th column
of matrix $\set{D}$. We denote by $\set{D}_{\set{i},\set{j}}$, where $\set{i}\subseteq
\left[1..n\right]$ and $\set{j}\subseteq\left[1..m\right]$ are sets of indices, a submatrix from
the extraction of the $\set{i}$ rows and $\set{j}$ columns of $\set{D}$. We use a colon as a
shorthand for selecting all rows or columns, e.g.\ $\set{D}_{:,:}=\set{D}$, $\set{D}_{:,j}$ is the
$j$-th column and $\set{D}_{i,:}$ is the $i$-th row.

\subsection{\textproc{LearnSPN}}

\begin{figure}[t]
  \begin{subfigure}[t]{0.48\textwidth}
    \begin{subfigure}{0.45\textwidth}
      \resizebox{\textwidth}{!}{
      \begin{tabular}{ccccc}
        \hline
        $A$ & $B$ & $C$ & $D$ & $E$\\
        \hline
        \rowcolor{boxgreen!70}
        0 & 1 & 0 & 0 & 1\\
        \rowcolor{boxgreen!70}
        1 & 0 & 1 & 1 & 1\\
        \rowcolor{boxblue!50}
        1 & 1 & 0 & 1 & 1\\
        \rowcolor{boxblue!50}
        0 & 0 & 1 & 0 & 0\\
        \rowcolor{boxgreen!70}
        1 & 1 & 0 & 1 & 0\\
        \rowcolor{boxblue!50}
        0 & 1 & 1 & 0 & 1\\
        \rowcolor{boxorange!60}
        1 & 0 & 1 & 1 & 1\\
        \rowcolor{boxorange!60}
        1 & 1 & 0 & 0 & 0\\
        \rowcolor{boxblue!50}
        0 & 1 & 1 & 0 & 1\\
        \hline
      \end{tabular}
      }
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
      \resizebox{\textwidth}{!}{
      \begin{tikzpicture}
        \newSumNode[fill=boxpink!50]{r}{0,0};
        \newProdNode[fill=boxgreen!70]{p1}{$(r) + (-1.5,-1.5)$};
        \newProdNode[fill=boxorange!60]{p2}{$(r) + (0,-1.5)$};
        \newProdNode[fill=boxblue!50]{p3}{$(r) + (1.5,-1.5)$};
        \draw[edge] (r) -- node[midway,above left] {$\frac{3}{9}$} (p1);
        \draw[edge] (r) -- node[midway,left] {$\frac{2}{9}$} (p2);
        \draw[edge] (r) -- node[midway,above right] {$\frac{4}{9}$} (p3);
      \end{tikzpicture}
      }
    \end{subfigure}
    \caption{}
  \end{subfigure}
  \begin{subfigure}[t]{0.48\textwidth}
    \begin{subfigure}{0.45\textwidth}
      \newcolumntype{x}{>{\columncolor{boxgreen!70}}c}
      \newcolumntype{y}{>{\columncolor{boxorange!60}}c}
      \newcolumntype{z}{>{\columncolor{boxblue!50}}c}
      \resizebox{\textwidth}{!}{
      \begin{tabular}{xyyzx}
        \hline
        \multicolumn{1}{c}{$A$} & \multicolumn{1}{c}{$B$} & \multicolumn{1}{c}{$C$} &
        \multicolumn{1}{c}{$D$} & \multicolumn{1}{c}{$E$}\\
        \hline
        0 & 1 & 0 & 0 & 1\\
        1 & 0 & 1 & 1 & 1\\
        1 & 1 & 0 & 1 & 1\\
        0 & 0 & 1 & 0 & 0\\
        1 & 1 & 0 & 1 & 0\\
        0 & 1 & 1 & 0 & 1\\
        1 & 0 & 1 & 1 & 1\\
        1 & 1 & 0 & 0 & 0\\
        0 & 1 & 1 & 0 & 1\\
        \hline
      \end{tabular}
      }
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
      \resizebox{\textwidth}{!}{
      \begin{tikzpicture}
        \newProdNode[fill=boxpink!50]{r}{0,0};
        \newSumNode[label=below:{$\{A,E\}$},fill=boxgreen!70]{s1}{$(r) + (-1.5,-1.5)$};
        \newSumNode[label=below:{$\{B,C\}$},fill=boxorange!60]{s2}{$(r) + (0,-1.5)$};
        \newSumNode[label=below:{$\{D\}$},fill=boxblue!50]{s3}{$(r) + (1.5,-1.5)$};
        \draw[edge] (r) -- (s1); \draw[edge] (r) -- (s2); \draw[edge] (r) -- (s3);
      \end{tikzpicture}
      }
    \end{subfigure}
    \caption{}
  \end{subfigure}
  \caption{\textproc{LearnSPN} assigns either rows (a) or columns (b) for sum and product nodes
    respectively. For sums, their edge weights are set proportionally to the assignments. For
    product children, scopes are defined by which columns are assigned to them.}
  \label{fig:learnspn}
\end{figure}

Recall the semantics of sum and product nodes in a smooth and decomposable probabilistic circuit.
A sum is a mixture of distributions $p(\set{X})=\sum_{i=1}^m w_i\cdot p_i(\set{X})$ whose children
scopes are all the same. A product is a factorization $p(\set{X}_1,\ldots,\set{X}_n)=\prod_{i=1}^n
p(\set{X}_i)$, implying that $\set{X}_i\indep\set{X}_j$ for $i,j\in [n]$ and $i\neq j$.
\textproc{LearnSPN} \citep{gens13} exploits these semantics in an intuitive and uncomplicated
manner: sum children are defined by sub-PCs learned from similar (by some arbitrary metric)
assignments, and product children are sub-PCs learned from data conditioned on the variables
defined by their scope. In practice, this means that, for a dataset $\set{D}\in\mathbb{R}^{m\times
n}$, sums assign rows to their children, while product children are assigned columns. This
procedures continues recursively until data are reduced to a $k\times 1$ matrix, in which case a
univariate distribution acting as input node is learned from it. This recursive procedure is shown
more formally in \Cref{alg:learnspn}.

\begin{algorithm}[t]
  \caption{\textproc{LearnSPN}}\label{alg:learnspn}
  \begin{algorithmic}[1]
    \Require Data $\set{D}$, whose columns are indexed by variables $\set{X}$
    \Ensure A smooth and decomposable probabilistic circuit learned from $\set{D}$
    \IIf{$|\set{X}|=1$}{\textbf{return} an input node learned from $\set{D}$}
    \NIElse
      \State Find scope partitions $\set{X}_1,\ldots,\set{X}_t\subseteq\set{X}$ st
        $\set{X}_i\indep\set{X}_j$ for $i\neq j$
      \IIf{$k>1$}{\textbf{return} $\prod_{j=1}^t \textproc{LearnSPN}(\set{D}_{:,\set{X}_j},
        \set{X}_j)$}
      \NIElse
        \State Find subsets of data $\set{x}_1,\ldots,\set{x}_k\subseteq\set{D}$ st all assignments
          within $\set{x}_i$ are all similar
        \State \textbf{return} $\sum_{i=1}^k \frac{|\set{x}_i|}{|\set{D}|}\cdot
          \textproc{LearnSPN}(\set{x}_i,\set{X})$
      \EndNIElse
    \EndNIElse
  \end{algorithmic}
\end{algorithm}

Notably, \citep{gens13} purposely does not strictly specify which techniques should be used for
assigning rows and columns, although they do provide empirical results on a particular form of
\textproc{LearnSPN} where row assignments are computed through EM clustering and products by
pairwise G-testing. Instead, they call the algorithm a \emph{schema} that incorporates several
actual learning algorithms whose concrete form depends on the choice of how to split data.

\subsubsection{Complexity}

To be able to analyze the complexity of \textproc{LearnSPN}, we assume a particular form where sums
are learned from $k$-means clustering, and products through pairwise G-testing. We know learning
sums is efficient: $k$-means takes $\bigo(n\cdot k\cdot m\cdot c)$ time, where $k$ is the number of
clusters and $c$ the number of iterations to be run. Products, on the other hand, are much more
costly. The naÃ¯ve approach would be to compute whether $X_i\indep X_j$ for every possible
combination. This is clearly quadratic on the number of variables
$\bigo\left(\binom{m}{2}=\frac{m!}{2\cdot (m-2)!}\right)$ assuming an $\bigo(1)$ oracle for
independence testing. In reality, G-test takes $\bigo(n\cdot m)$ time, as we must compute a ratio
of observed versus expected values for each cell in the contingency table. This brings the total
runtime for products to a whopping $\bigo\left(n\cdot m^3\right)$, prohibitive to any reasonably
large dataset.

Alternatively, instead of computing the G-test for every possible combination of variables,
\citep{gens13} constructs an independence graph $\mathcal{G}$ whose nodes are variables and edges
indicate whether two variables are statistically dependent. Within this context, the variable
partitions we attribute to product children are exactly the connected components of $\mathcal{G}$,
meaning it suffices testing only some combinations. Even so, this heuristic is still quadratic
worst case.

\subsubsection{Pros and cons}

\paragraph{Pros.} Perhaps the main factor for \textproc{LearnSPN}'s popularity is how easily
implementable, intuitive and modular it is. Even more remarkably, it is an empirically competitive
PC learning algorithm despite its age, serving as a baseline for most subsequent works in PC
literature. Lastly, the fact that each recursive call from \textproc{LearnSPN} is completely
independent from each the other makes it an attractive candidate for CPU parallelization.

\paragraph{Cons.} Debatably, one of the key weakness of \textproc{LearnSPN} is its tree-shaped
computational graph, meaning that they are strictly less expressive compared to non-tree DAG PCs
\citep{martens14}. In terms of runtime efficiency, the algorithm struggles on high dimensional
data due to the complexity involved in computing costly statistical tests. Despite
\Cref{alg:learnspn} giving the impression that no hyperparameter tuning is needed for
\textproc{LearnSPN}, in practice the modules for learning sums and products often take many
parameters, most of which are fixed for all recursive calls. This can have a negative impact on the
algorithm's performance, since even when data might have completely different shapes between calls
the same parameters are used repeatedly.

\subsection{\textproc{ID-SPN}}

A subtle but effective way of improving the performance of \textproc{LearnSPN} is to consider
tractable probabilistic models over many variables as input nodes instead of a single univariate
distribution. \textproc{ID-SPN} \citep{rooshenas14} does so by assuming that input nodes are Markov
networks. Further, instead of blindly applying the recursion over subsequent sub-data, it attempts
to compute some metric of quality from each node. The worst scored node is then replaced with a
\textproc{LearnSPN}-like tree. This is repeated until no significant increase in likelihood is
observed. \Cref{alg:idspn} shows the \textproc{ID-SPN} pipeline, where \textproc{ExtendID} is used
in line \ref{alg:idspn:line:extend} to grow the circuit in a divide-and-conquer fashion.

\begin{algorithm}[t]
  \caption{\textproc{ExtendID}}\label{alg:extendid}
  \begin{algorithmic}[1]
    \Require Data $\set{D}$, whose columns are indexed by variables $\set{X}$, and memoization
      function $\mathcal{M}$
    \Ensure A smooth and decomposable probabilistic circuit learned from $\set{D}$
    \State Find scope partitions $\set{X}_1,\ldots,\set{X}_t\subseteq\set{X}$ st
    \If{$k>1$}
      \For{each $j\in\left[t\right]$}
        \State $\Node_j\gets\textproc{LearnMarkov}(\set{D}_{:,\set{X}_j},\set{X}_j)$
        \State Associate $\mathcal{M}(\Node_j)$ with $\set{D}_{:,\set{X}_j}$ and $\set{X}_j$
      \EndFor
      \State \textbf{return} $\prod_{j=1}^t \Node_j$
    \Else
      \State Find subsets of data $\set{x}_1,\ldots,\set{x}_k\subseteq\set{D}$ st all assignments
        within $\set{x}_i$ are all similar
      \For{each $i\in\left[k\right]$}
        \State $\Node_i\gets\textproc{LearnMarkov}(\set{x}_i,\set{X})$
        \State Associate $\mathcal{M}(\Node_i)$ with $\set{x}_i$ and $\set{X}$
      \EndFor
      \State \textbf{return} $\sum_{i=1}^k \frac{|\set{x}_i|}{|\set{D}|}\cdot\Node_i$
    \EndIf
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}[t]
  \caption{\textproc{ID-SPN}}\label{alg:idspn}
  \begin{algorithmic}[1]
    \Require Data $\set{D}$, whose columns are indexed by variables $\set{X}$
    \Ensure A smooth and decomposable probabilistic circuit learned from $\set{D}$
    \State Create a single-node PC: $\mathcal{C}\gets\textproc{LearnMarkov}(\set{D},\set{X})$
    \State Let $\mathcal{M}$ a memoization function associating a node with a dataset and scope
    \State Call $\mathcal{C}'$ a copy of $\mathcal{C}$
    \While{improving $\mathcal{C}$ yields better likelihood}
      \State Pick worse node $\Node$ from $\mathcal{C}'$
      \State Extract sub-data $\set{D}'$ and sub-scope $\set{X}'$ from $\mathcal{M}(\Node)$
      \State Replace $\Node$ with $\textproc{ExtendID}(\set{D}',\set{X}',\mathcal{M})$\label{alg:idspn:line:extend}
      \IIf{$\mathcal{C}'$ has better likelihood than $\mathcal{C}$}{$\mathcal{C}\gets\mathcal{C}$}
    \EndWhile
    \State \textbf{return} $\mathcal{C}$
  \end{algorithmic}
\end{algorithm}

\subsection{\textproc{Prometheus}}


\section{Iterative Learning}
\label{sec:iterative}

\section{Random Learning}
\label{sec:random}
