%!TeX root=../tese.tex

\chapter{Appendix}

\section{Proofs}

\begin{theorem}
  \label{thm:summix}
  Let $\mathcal{C}$ a probabilistic circuit whose first $l$ layers are composed solely of sum
  nodes. Call $\Nodes$ the set of all nodes in layer $l+1$. $\mathcal{C}$ is equivalent to a PC
  $\mathcal{C}'$ whose root is a sum node with $\Nodes$ as children.
\end{theorem}
\begin{proof}
  We adapt a similar proof due to \citet{jaini18b}. Every sum node is of the form
  \begin{equation*}
    \Sum(\set{x})=\sum_{\Child\in\Ch(\Sum)}w_{\Sum,\Child}\cdot\Child(\set{x}).
  \end{equation*}
  Particularly, every child $\Child$ in a sum node in layer $1\leq i\leq l-1$, is a sum node, and
  so for the first layer we have that
  \begin{align*}
    \Sum(\set{x})&=\sum_{\Child_1\in\Ch(\Sum)}w_{\Sum,\Child_1}\sum_{\Child_2\in\Ch(\Child_1)}
    w_{\Child_1,\Child_2}\Child_2(\set{x})\\
                 &=\sum_{\Child_1\in\Ch(\Sum)}\sum_{\Child_2\in\Ch(\Child_1)}w_{\Sum,\Child_1}
    w_{\Child_1,\Child_2}\Child_2(\set{x}).
  \end{align*}
  Define a one-to-one mapping that takes a tuple $(\Child_1,\Child_2)$ where $\Child_1\in\Ch(\Sum)$
  and $\Child_2\in\Ch(\Child_1)$ and returns a (unique) path from $\Sum$ to every grandchild
  $\Child_2$ of $\Sum$. Call $\set{K}$ the set of all paths, and $w_{\Sum,\Child_1}$ and
    $w_{\Child_1,\Child_2}$ the weights for one such path. We can merge these two weights into a
  single weight $w_{\Sum,\Child_2}'= w_{\Sum,\Child_1}\cdot w_{\Child_1,\Child_2}$, yielding
  \begin{equation*}
    \Sum(\set{x})=\sum_{(w_{\Sum,\Child_1},w_{\Child_1,\Child_2})\in\set{K}} w_{\Sum,\Child_2}'
    \Child_2(\set{x}).
  \end{equation*}
  This ensures that two consecutive sum layers can be collapsed into a single layer. Particularly,
  for the first (root) and second layers, the above transformation generates a circuit with one
  fewer layer and whose root has $\bigo(nm)$ edges, where $n$ and $m$ are the number of edges coming
  from the original root and its children respectively. We can apply this procedure until there are
  no more consecutive sum nodes. This results in a PC of the form
  \begin{equation*}
    \Sum(\set{x})=\sum_{\Child\in\Ch(S)} w_{\Sum,\Child}\Node(\set{x}),
  \end{equation*}
  where $\Node\in\Nodes$. The number of children of the resulting root sum node will be exponential
  on the number of edges of its children.
\end{proof}

\begin{theorem}[Standardization]
  \label{thm:standard}
  Any probabilistic circuit $\mathcal{C}$ can be reduced to a circuit where every sum node contains
  only products or inputs and every product node contains only sums or inputs.
\end{theorem}
\begin{proof}
  If $\mathcal{C}$ is already standard we are done. Otherwise, there exists either (i) a sum node
  $\Sum$ with a sum $\Sum'$ as child; or (ii) a product node $\Prod$ with a product $\Prod'$ as
  child. We first address (i): let $w$ be the weight of edge $\edge{\Sum\Sum'}$ and $\theta_i$
  the weights from all edges coming out from $\Sum'$.
  \begin{center}
    \begin{tikzpicture}
      \newSumNode[label=above right:{$\Sum$}]{s}{0,0};
      \newProdNode{p1}{$(s) + (-1.25,-1)$};
      \newSumNode[label=above left:{$\Sum'$}]{sl}{$(s) + (0,-1.5)$};
      \newProdNode{p2}{$(s) + (1.25,-1)$};
      \newProdNode{q1}{$(sl) + (-1.25,-1)$};
      \newProdNode{q2}{$(sl) + (0,-1)$};
      \newProdNode{q3}{$(sl) + (1.25,-1)$};
      \draw[edge] (s) edge (p1);
      \draw[edge] (s) edge node[midway,right] {\scriptsize$w$} (sl);
      \draw[edge] (s) edge (p2);
      \draw[edge] (sl) edge node[midway,left] {\scriptsize$\theta_1$} (q1);
      \draw[edge] (sl) edge node[midway,left] {\scriptsize$\theta_2$} (q2);
      \draw[edge] (sl) edge node[midway,left] {\scriptsize$\theta_3$} (q3);

      \draw[edge,very thick,red] (2.25,-1.5) -- node[midway,above] {Standardize} (5.5,-1.5);

      \newSumNode[label=above right:{$\Sum$}]{s}{8,0};
      \newProdNode{p1}{$(s) + (-1.5,-1.0)$};
      \newProdNode{p2}{$(s) + (1.5,-1.0)$};
      \newProdNode{q1}{$(s) + (-1.5,-2.5)$};
      \newProdNode{q2}{$(s) + (-0,-2.5)$};
      \newProdNode{q3}{$(s) + (1.5,-2.5)$};
      \draw[edge] (s) edge (p1);
      \draw[edge] (s.south) -- ++(0,-1.25) -| node[midway,below right] {\scriptsize$w\cdot\theta_1$} (q1);
      \draw[edge] (s.south) -- ++(0,-1.25) -| node[midway,below right] {\scriptsize$w\cdot\theta_2$} (q2);
      \draw[edge] (s.south) -- ++(0,-1.25) -| node[midway,below right] {\scriptsize$w\cdot\theta_3$} (q3);
      \draw[edge] (s) edge (p2);
    \end{tikzpicture}
  \end{center}
  Connect $\Sum$ with every child of $\Sum'$, assigning as weight $w\cdot\theta_i$ for each child
  $i$. Delete $\Sum'$ and all edges coming out from it. The resulting circuit is computationally
  equivalent but now without a consecutive pair of sums. This transformation is visualized by the
  figure above. We do a similar procedure in (ii), but now instead remove $\Prod'$ and connect all
  children of $\Prod'$ to $\Prod$, as we show below.
  \begin{center}
    \begin{tikzpicture}
      \newProdNode[label=above right:{$\Prod$}]{s}{0,0};
      \newSumNode{p1}{$(s) + (-1.25,-1)$};
      \newProdNode[label=above left:{$\Prod'$}]{sl}{$(s) + (0,-1.5)$};
      \newSumNode{p2}{$(s) + (1.25,-1)$};
      \newSumNode{q1}{$(sl) + (-1.25,-1)$};
      \newSumNode{q2}{$(sl) + (0,-1)$};
      \newSumNode{q3}{$(sl) + (1.25,-1)$};
      \draw[edge] (s) edge (p1);
      \draw[edge] (s) edge (sl);
      \draw[edge] (s) edge (p2);
      \draw[edge] (sl) edge (q1);
      \draw[edge] (sl) edge (q2);
      \draw[edge] (sl) edge (q3);

      \draw[edge,very thick,red] (2.25,-1.5) -- node[midway,above] {Standardize} (5.5,-1.5);

      \newProdNode[label=above right:{$\Prod$}]{s}{8,0};
      \newSumNode{p1}{$(s) + (-1.5,-1.0)$};
      \newSumNode{p2}{$(s) + (1.5,-1.0)$};
      \newSumNode{q1}{$(s) + (-1.5,-2.5)$};
      \newSumNode{q2}{$(s) + (-0,-2.5)$};
      \newSumNode{q3}{$(s) + (1.5,-2.5)$};
      \draw[edge] (s) edge (p1);
      \draw[edge] (s.south) -- ++(0,-1.25) -| (q1);
      \draw[edge] (s.south) -- ++(0,-1.25) -| (q2);
      \draw[edge] (s.south) -- ++(0,-1.25) -| (q3);
      \draw[edge] (s) edge (p2);
    \end{tikzpicture}
  \end{center}
\end{proof}

\begin{theorem}[2-Standardization]
\label{thm:2standard}
Any probabilistic circuit $\mathcal{C}$ can be transformed into a circuit where every sum node
contains only products or inputs and every product node contains only \emph{two} sums or inputs.
\end{theorem}
\begin{proof}
  For sums, apply the same standardization procedure as \cref{thm:standard}. Let $\Prod$ a product
  and call $n=|\Ch(\Prod)|$. If $n=1$ and $\Ch(\Prod)$ is a product, then remove $\Prod$ and
  connect all previous parents of $\Prod$ with its child. If $n=1$ and $\Ch(\Prod)$ is not a
  product, remove $\Prod$ and apply the standardization procedure for sums on all of $\Pa(\Prod)$.

  For $n>2$, we simply need to split into 2-products recursively. We prove this by induction. The
  base case is when $n=2$, which is already done, or $n=3$, in which case we need apply the
  transformation below.
  \begin{center}
    \begin{tikzpicture}
      \newProdNode{r}{0,0};
      \newSumNode{s1}{$(r) + (-1.5,-2)$};
      \newSumNode{s2}{$(r) + (0,-2)$};
      \newSumNode{s3}{$(r) + (1.5,-2)$};
      \draw[edge] (r) -- (s1);
      \draw[edge] (r) -- (s2);
      \draw[edge] (r) -- (s3);

      \draw[edge,very thick,red] (2.25,-0.5) -- node[midway,above] {2-Standardize} (5.5,-0.5);

      \newProdNode{r}{7,0};
      \newSumNode[fill=boxorange!80]{t}{$(r) + (-0.5,-1)$};
      \newSumNode{s1}{$(r) + (0.5,-1)$};
      \newProdNode[fill=boxgoldenrod!70]{p}{$(t) + (-0.5,-1)$};
      \newSumNode{s2}{$(p) + (-0.5,-1)$};
      \newSumNode{s3}{$(p) + (0.5,-1)$};
      \draw[edge] (r) -- (t);
      \draw[edge] (r) -- (s1);
      \draw[edge] (t) -- (p);
      \draw[edge] (p) -- (s2);
      \draw[edge] (p) -- (s3);
    \end{tikzpicture}
  \end{center}
  Where \inode[fill=boxorange!80]{\newSumNode} and \inode[fill=boxgoldenrod!70]{\newProdNode} are
  newly introduced nodes. When $n>3$, we create two products $\Prod_1$ and $\Prod_2$, each
  connected with a sum and product, and with $\left\lfloor\frac{n}{2}\right\rfloor$ and
  $\left\lceil\frac{n}{2}\right\rceil$ potential children. By the induction hypothesis, we can
  recursively binarize the subsequent grandchildren products.
  \begin{center}
    \begin{tikzpicture}
      \newProdNode{r}{0,0};
      \newSumNode{s1}{$(r) + (-2,-2)$};
      \newSumNode{s2}{$(r) + (-1,-2)$};
      \newSumNode{s3}{$(r) + (0,-2)$};
      \newSumNode{s4}{$(r) + (1,-2)$};
      \newSumNode{s5}{$(r) + (2,-2)$};
      \draw[edge] (r) -- (s1);
      \draw[edge] (r) -- (s2);
      \draw[edge] (r) -- (s3);
      \draw[edge] (r) -- (s4);
      \draw[edge] (r) -- (s5);

      \draw[edge,very thick,red] (2.25,-0.5) -- node[midway,above] {2-Standardize} (5.5,-0.5);

      \newProdNode{r}{7,0};
      \newSumNode[fill=boxorange!80]{t1}{$(r) + (-0.5,-1)$};
      \newSumNode[fill=boxorange!80]{t2}{$(r) + (0.5,-1)$};
      \newProdNode[fill=boxgoldenrod!70]{p1}{$(t1) + (-0.5,-1)$};
      \newProdNode[fill=boxgoldenrod!70]{p2}{$(t2) + (0.5,-1)$};
      \newSumNode{s1}{$(p1) + (-0.5,-1)$};
      \newSumNode{s2}{$(p1) + (0.5,-1)$};
      \newSumNode{s3}{$(p2) + (-0.75,-1)$};
      \newSumNode{s4}{$(p2) + (0.0,-1)$};
      \newSumNode{s5}{$(p2) + (0.75,-1)$};
      \draw[edge] (r) -- (t1);
      \draw[edge] (r) -- (t2);
      \draw[edge] (t1) -- (p1);
      \draw[edge] (t2) -- (p2);
      \draw[edge] (p1) -- (s1);
      \draw[edge] (p1) -- (s2);
      \draw[edge] (p2) -- (s3);
      \draw[edge] (p2) -- (s4);
      \draw[edge] (p2) -- (s5);
    \end{tikzpicture}
  \end{center}
  As an example, we have $n=5$ in the figure above. We introduce the sums
  \inode[fill=boxorange!80]{\newSumNode} and products \inode[fill=boxgoldenrod!70]{\newProdNode}
  and then recursively apply the transformation again on the
  \inode[fill=boxgoldenrod!70]{\newProdNode}s.

  When $\Ch(\Prod)$ are product nodes we do the same procedure as before, but with the added
  post-process addition of a sum node connecting \inode[fill=boxgoldenrod!70]{\newProdNode} to
  every $\Ch(\Prod)$.
\end{proof}

\linevi*
\begin{proof}
  \label{proof:linevi}
  For a sum node $\Sum$, we have the following marginalization query
  \begin{align*}
    \int\Sum(\set{x},\set{y})\dif\set{y}&=\int\sum_{\Child\in\Ch(\Sum)}w_{\Sum,\Child}\Child(\set{x},\set{y})\dif\set{y}\\
                                        &=\sum_{\Child\in\Ch(\Sum)}w_{\sum,\Child}\int\Child(\set{x},\set{y})\dif\set{y}.
  \end{align*}
  Analogously, for a product node
  \begin{align*}
    \int\Prod(\set{x},\set{y})\dif\set{y}&=\int\prod_{\Child\in\Ch(\Prod)}\Child(\set{x},\set{y})\dif\set{y}\\
                                         &=\prod_{\Child\in\Ch(\Prod)}\int\Child(\set{x},\set{y})\dif\set{y}.
  \end{align*}
  This ensures that marginals are pushed down to children. This can be done recursively until
  $\Child$ is an input node $\Leaf_p$, in which case we marginalize $\set{y}$ according to $p$,
  which by definition should be tractable and here we assume can be done in $\bigo(1)$. We have
  proved the case for \mar{}. For \evi{}, we simply assign $\set{y}=\emptyset$ with input nodes
  acting as probability density functions. Conditionals can easily be computed by an \evi{} or
  \mar{} followed by a second pass marginalizing the conditional variables
  $p(\set{x}|\set{y})=\frac{p(\set{x},\set{y})}{p(\set{y})}$ which are both done in linear time as
  we have seen here.
\end{proof}

\det*
\begin{proof}
  \label{proof:det}
  For a sum node $\Sum$, we want to compute the following query
  \begin{equation*}
    \max_{\set{y}}\Sum(\set{y}|\set{x})=\frac{1}{\Sum(\set{x})}\max_{\set{y}}\Sum(\set{y},\set{x})
    =\frac{1}{\Sum(\set{x})}\max_{\set{y}}\sum_{\Child\in\Ch(\Sum)}w_{\Sum,\Child}\Child(\set{y},\set{x}),
  \end{equation*}
  yet notice that for any assignment of $\set{x}$ and $\set{y}$ only one $\Child\in\Ch(\Sum)$ must
  have a nonnegative value by the definition of determinism, so we may replace the summation with
  a maximization over the children, giving
  \begin{equation*}
    \max_{\set{y}}\Sum(\set{y}|\set{x})=\frac{1}{\Sum(\set{x})}\max_{\set{y}}\max_{\Child\in\Ch(\Sum)}w_{\Sum,\Child}\Child(\set{y},\set{x})
    =\frac{1}{\Sum(\set{x})}\max_{\Child\in\Ch(\Sum)}\max_{\set{y}}w_{\Sum,\Child}\Child(\set{y},\set{x}).
  \end{equation*}
  For a product node $\Prod$, we compute
  \begin{align*}
    \max_{\set{y}}\Prod(\set{y}|\set{x})=\frac{1}{\Prod(\set{x})}\max_{\set{y}}\Prod(\set{y},\set{x})
    =\frac{1}{\Prod(\set{x})}\max_{\set{y}}\prod_{\Child\in\Ch(\Prod)}\Child(\set{y},\set{x})
    =\frac{1}{\Prod(\set{x})}\prod_{\Child\in\Ch(\Prod)}\max_{\set{y}}\Child(\set{y},\set{x}).
  \end{align*}
  This is equivalent to an inductive top-down pass where we maximize instead of sum until we reach
  all input nodes, in which case we simply maximize the supposedly tractable functions. Once these
  are computed, we unroll the induction, maximizing over all values.
\end{proof}
